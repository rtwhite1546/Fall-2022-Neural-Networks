{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4\n",
    "\n",
    "# Lecture 7 - Sept 14 - Implementing Backpropagation\n",
    "\n",
    "Below, we implement a fully-connected feedforward neural network with random weight initialization, customizable architecture, and gradient descent with use of backpropagation for computing the gradients. We will then test it on some examples.\n",
    "\n",
    "The best way to understand how this all works is to actually implement it with minimal external libraries. One exception is `NumPy`, which at least automates some of the basic mathematical operations we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will implement the feedforward neural network. The code is partly based on an implementation from *Deep Learning for Computer Vision with Python* by Adrian Rosebrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetwork:\n",
    "    \n",
    "    # input a vector [a, b, c, ...] with the number of nodes in each layer\n",
    "    def __init__(self, layers, alpha = 0.1):\n",
    "        \n",
    "        # list of weight matrices between layers\n",
    "        self.W = []\n",
    "        \n",
    "        # network architecture will be a vector of numbers of nodes for each layer\n",
    "        self.layers = layers\n",
    "        \n",
    "        # learning rate\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # initialize the weights (randomly) -- this is our initial guess for gradient descent\n",
    "        \n",
    "        # initialize the weights between layers (up to the next-to-last one) as normal random variables\n",
    "        for i in np.arange(0, len(layers) - 2):\n",
    "            self.W.append(np.random.randn(layers[i] + 1, layers[i + 1] + 1))\n",
    "            \n",
    "        # initialize weights between the last two layers (we don't want bias for the last one)\n",
    "        self.W.append(np.random.randn(layers[-2] + 1, layers[-1]))\n",
    "        \n",
    "    # define the sigmoid activation\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    # define the sigmoid derivative (where z is the output of a sigmoid)\n",
    "    def sigmoidDerivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    # fit the model\n",
    "    def fit(self, X, y, epochs = 10000, update = 1000):\n",
    "        # add a column of ones to the end of X\n",
    "        X = np.hstack((X, np.ones([X.shape[0],1])))\n",
    "\n",
    "        for epoch in np.arange(0,epochs):\n",
    "\n",
    "            # feed forward, backprop, and weight update\n",
    "            for (x, target) in zip(X, y):\n",
    "                \n",
    "                # make a list of output activations from the first layer\n",
    "                # (just the original x values)\n",
    "                A = [np.atleast_2d(x)]\n",
    "                \n",
    "                # feed forward\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    \n",
    "                    # feed through one layer and apply sigmoid activation\n",
    "                    net = A[layer].dot(self.W[layer])\n",
    "                    out = self.sigmoid(net)\n",
    "                    \n",
    "                    # add our network output to the list of activations\n",
    "                    A.append(out)\n",
    "                    \n",
    "                # backpropagation\n",
    "                error = A[-1] - target\n",
    "                \n",
    "                # term proportional to the gradient\n",
    "                D = [error * self.sigmoidDerivative(A[-1])]\n",
    "                \n",
    "                # loop backwards over the layers to build up deltas\n",
    "                for layer in np.arange(len(A) - 2, 0, -1):\n",
    "                    delta = D[-1].dot(self.W[layer].T)\n",
    "                    delta = delta * self.sigmoidDerivative(A[layer])\n",
    "                    D.append(delta)\n",
    "                    \n",
    "                # reverse the deltas since we looped in reverse\n",
    "                D = D[::-1]\n",
    "                \n",
    "                # weight update\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    self.W[layer] -= self.alpha * A[layer].T.dot(D[layer])\n",
    "                    \n",
    "            # print a status update\n",
    "            if (epoch + 1) % update == 0:\n",
    "                loss = self.computeLoss(X,y)\n",
    "                print('Epoch =', epoch + 1, 'loss = ', loss)\n",
    "                \n",
    "    def predict(self, X, addOnes = True):\n",
    "        # initialize data, be sure it's the right dimension\n",
    "        p = np.atleast_2d(X)\n",
    "        \n",
    "        # add a column of 1s for bias\n",
    "        if addOnes:\n",
    "            p = np.hstack((p, np.ones([X.shape[0],1])))\n",
    "        \n",
    "        # feed forward!\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
    "         \n",
    "        # return the predictions\n",
    "        return p\n",
    "    \n",
    "    def computeLoss(self, X, y):\n",
    "        # initialize data, be sure it's the right dimension\n",
    "        y = np.atleast_2d(y)\n",
    "        \n",
    "        # feed the datapoints through the network to get predicted outputs\n",
    "        predictions = self.predict(X, addOnes = False)\n",
    "        \n",
    "        # compute the sum of squared errors loss function\n",
    "        loss = np.sum((predictions - y)**2) / 2.0\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the variables of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': [array([[-1.54358744, -0.29704487,  0.13394198],\n",
       "         [ 0.25962225, -0.4510906 ,  2.76438093],\n",
       "         [-0.665133  ,  0.46708451, -0.80372408]]),\n",
       "  array([[ 1.66290868],\n",
       "         [-0.80965392],\n",
       "         [ 0.60145251]])],\n",
       " 'layers': [2, 2, 1],\n",
       " 'alpha': 0.1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedforwardNeuralNetwork([2, 2, 1])\n",
    "vars(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: XOR function\n",
    "\n",
    "Let's run the code to try to learn the exclusive 'or' function, i.e. XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 10000 loss =  0.0004366847890715098\n",
      "Epoch = 20000 loss =  0.00036735424273988816\n",
      "Epoch = 30000 loss =  0.0003171054597651407\n",
      "Epoch = 40000 loss =  0.00027897632486613877\n",
      "Epoch = 50000 loss =  0.0002490376592788722\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "random.seed(1)\n",
    "model.fit(X,y,50000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00675055],\n",
       "       [0.98987284],\n",
       "       [0.9868278 ],\n",
       "       [0.01328304]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note these are very close to 0, 1, 1, 0 -- the correct classifications for the XOR function. This neural net can classify this nonlinear problem of XOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Tiny MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some more libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to classify a tiny version of the MNIST data shrunk down to 8-by-8 pixel images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 1797, Dimension: 64\n",
      "Epoch = 100 loss =  30.025955074503685\n",
      "Epoch = 200 loss =  36.21394026638919\n",
      "Epoch = 300 loss =  15.26937321928396\n",
      "Epoch = 400 loss =  12.746748281488209\n",
      "Epoch = 500 loss =  12.177533010552425\n",
      "Epoch = 600 loss =  11.5263636544302\n",
      "Epoch = 700 loss =  11.238358218975065\n",
      "Epoch = 800 loss =  11.039997228785815\n",
      "Epoch = 900 loss =  10.886201010325982\n",
      "Epoch = 1000 loss =  10.761466862816421\n",
      "Training set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       136\n",
      "           1       0.97      0.99      0.98       139\n",
      "           2       0.99      1.00      1.00       131\n",
      "           3       1.00      1.00      1.00       135\n",
      "           4       1.00      0.98      0.99       125\n",
      "           5       0.99      0.99      0.99       141\n",
      "           6       0.99      1.00      0.99       143\n",
      "           7       0.99      1.00      0.99       135\n",
      "           8       0.98      0.95      0.97       130\n",
      "           9       0.99      0.97      0.98       132\n",
      "\n",
      "    accuracy                           0.99      1347\n",
      "   macro avg       0.99      0.99      0.99      1347\n",
      "weighted avg       0.99      0.99      0.99      1347\n",
      "\n",
      "Test set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        42\n",
      "           1       0.95      0.95      0.95        43\n",
      "           2       0.90      0.98      0.94        46\n",
      "           3       0.90      0.94      0.92        48\n",
      "           4       1.00      0.96      0.98        56\n",
      "           5       0.95      0.98      0.96        41\n",
      "           6       0.97      1.00      0.99        38\n",
      "           7       0.98      1.00      0.99        44\n",
      "           8       0.88      0.84      0.86        44\n",
      "           9       0.96      0.90      0.92        48\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.95      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### CLASSIFY MNIST PICTURES\n",
    "\n",
    "# 'digits' is a tiny version of MNIST in sklearn.datasets has only 8 x 8 pixels\n",
    "# with grayscale values from 0 to 16\n",
    "digits = datasets.load_digits()\n",
    "data = digits.data.astype(\"float\")\n",
    "print(\"Samples: {}, Dimension: {}\".format(data.shape[0], data.shape[1]))\n",
    "\n",
    "X = data\n",
    "\n",
    "Y = digits.target\n",
    "\n",
    "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# we need to turn the labels into 1-hot representations\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# fit the model to the training data\n",
    "model = FeedforwardNeuralNetwork([64, 16, 10])\n",
    "model.fit(trainX,trainY,1000,100)\n",
    "\n",
    "# print the classification performance\n",
    "print(\"Training set accuracy\")\n",
    "\n",
    "predictedY = model.predict(trainX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "trainY = trainY.argmax(axis=1)\n",
    "\n",
    "print(classification_report(trainY, predictedY))\n",
    "\n",
    "print(\"Test set accuracy\")\n",
    "\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "testY = testY.argmax(axis=1)\n",
    "\n",
    "print(classification_report(testY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 1797, Dimension: 64\n",
      "Epoch = 10 loss =  127.06523498806862\n",
      "Epoch = 20 loss =  51.03129409953402\n",
      "Epoch = 30 loss =  30.656671992238223\n",
      "Epoch = 40 loss =  20.340515472015575\n",
      "Epoch = 50 loss =  14.377298027602196\n",
      "Epoch = 60 loss =  10.913532923990282\n",
      "Epoch = 70 loss =  8.685824247989864\n",
      "Epoch = 80 loss =  7.086230254489341\n",
      "Epoch = 90 loss =  5.603749803065613\n",
      "Epoch = 100 loss =  4.672016132736114\n",
      "Epoch = 110 loss =  4.0377832167869405\n",
      "Epoch = 120 loss =  3.526720562817067\n",
      "Epoch = 130 loss =  2.9034191918371164\n",
      "Epoch = 140 loss =  2.537034662913965\n",
      "Epoch = 150 loss =  2.2654080521567557\n",
      "Epoch = 160 loss =  2.026486303369377\n",
      "Epoch = 170 loss =  1.7849971919961145\n",
      "Epoch = 180 loss =  1.5510355711975108\n",
      "Epoch = 190 loss =  1.378364041131031\n",
      "Epoch = 200 loss =  1.2492594511593789\n",
      "Epoch = 210 loss =  1.1454205604431669\n",
      "Epoch = 220 loss =  1.0586349566938593\n",
      "Epoch = 230 loss =  0.9844530661613339\n",
      "Epoch = 240 loss =  0.9200700855591448\n",
      "Epoch = 250 loss =  0.8635492667666217\n",
      "Epoch = 260 loss =  0.8134755648755476\n",
      "Epoch = 270 loss =  0.7687754830787938\n",
      "Epoch = 280 loss =  0.7286124356648527\n",
      "Epoch = 290 loss =  0.6923210318751194\n",
      "Epoch = 300 loss =  0.6593634042949992\n",
      "Epoch = 310 loss =  0.6292989387336299\n",
      "Epoch = 320 loss =  0.6017626022421034\n",
      "Epoch = 330 loss =  0.5764490234319054\n",
      "Epoch = 340 loss =  0.553100551317323\n",
      "Epoch = 350 loss =  0.5314981410971551\n",
      "Epoch = 360 loss =  0.5114542939304757\n",
      "Epoch = 370 loss =  0.4928075173983618\n",
      "Epoch = 380 loss =  0.4754179300572769\n",
      "Epoch = 390 loss =  0.45916373884980277\n",
      "Epoch = 400 loss =  0.44393839066442425\n",
      "Epoch = 410 loss =  0.4296482502869652\n",
      "Epoch = 420 loss =  0.4162106934203516\n",
      "Epoch = 430 loss =  0.40355252991120866\n",
      "Epoch = 440 loss =  0.39160869180894997\n",
      "Epoch = 450 loss =  0.3803211354118061\n",
      "Epoch = 460 loss =  0.3696379174080243\n",
      "Epoch = 470 loss =  0.3595124135626637\n",
      "Epoch = 480 loss =  0.3499026548129359\n",
      "Epoch = 490 loss =  0.34077076060630734\n",
      "Epoch = 500 loss =  0.33208245319960944\n",
      "Epoch = 510 loss =  0.32380663969486034\n",
      "Epoch = 520 loss =  0.31591505100993295\n",
      "Epoch = 530 loss =  0.30838192891439375\n",
      "Epoch = 540 loss =  0.3011837538108154\n",
      "Epoch = 550 loss =  0.29429900719262114\n",
      "Epoch = 560 loss =  0.2877079637237051\n",
      "Epoch = 570 loss =  0.28139250871217936\n",
      "Epoch = 580 loss =  0.27533597742778326\n",
      "Epoch = 590 loss =  0.2695230132698707\n",
      "Epoch = 600 loss =  0.26393944225340776\n",
      "Epoch = 610 loss =  0.25857216166253627\n",
      "Epoch = 620 loss =  0.2534090410396562\n",
      "Epoch = 630 loss =  0.24843883394408026\n",
      "Epoch = 640 loss =  0.24365109913774904\n",
      "Epoch = 650 loss =  0.23903613004363708\n",
      "Epoch = 660 loss =  0.23458489148122483\n",
      "Epoch = 670 loss =  0.23028896281832512\n",
      "Epoch = 680 loss =  0.22614048679291418\n",
      "Epoch = 690 loss =  0.2221321233562553\n",
      "Epoch = 700 loss =  0.21825700797216285\n",
      "Epoch = 710 loss =  0.21450871387876763\n",
      "Epoch = 720 loss =  0.21088121788067235\n",
      "Epoch = 730 loss =  0.20736886929240855\n",
      "Epoch = 740 loss =  0.20396636170001714\n",
      "Epoch = 750 loss =  0.2006687072470822\n",
      "Epoch = 760 loss =  0.19747121318609856\n",
      "Epoch = 770 loss =  0.19436946046601702\n",
      "Epoch = 780 loss =  0.1913592841528118\n",
      "Epoch = 790 loss =  0.18843675550290281\n",
      "Epoch = 800 loss =  0.18559816552904065\n",
      "Epoch = 810 loss =  0.18284000991593186\n",
      "Epoch = 820 loss =  0.18015897515820295\n",
      "Epoch = 830 loss =  0.17755192580685628\n",
      "Epoch = 840 loss =  0.17501589272232257\n",
      "Epoch = 850 loss =  0.17254806224278474\n",
      "Epoch = 860 loss =  0.17014576618577731\n",
      "Epoch = 870 loss =  0.1678064726093373\n",
      "Epoch = 880 loss =  0.16552777726636778\n",
      "Epoch = 890 loss =  0.16330739569238825\n",
      "Epoch = 900 loss =  0.16114315587264752\n",
      "Epoch = 910 loss =  0.15903299143983213\n",
      "Epoch = 920 loss =  0.15697493535815488\n",
      "Epoch = 930 loss =  0.1549671140538461\n",
      "Epoch = 940 loss =  0.1530077419557297\n",
      "Epoch = 950 loss =  0.15109511641287504\n",
      "Epoch = 960 loss =  0.149227612959392\n",
      "Epoch = 970 loss =  0.1474036808990507\n",
      "Epoch = 980 loss =  0.1456218391848698\n",
      "Epoch = 990 loss =  0.1438806725709534\n",
      "Epoch = 1000 loss =  0.1421788280159068\n",
      "Training set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       132\n",
      "           1       1.00      1.00      1.00       134\n",
      "           2       1.00      1.00      1.00       127\n",
      "           3       1.00      1.00      1.00       148\n",
      "           4       1.00      1.00      1.00       135\n",
      "           5       1.00      1.00      1.00       133\n",
      "           6       1.00      1.00      1.00       137\n",
      "           7       1.00      1.00      1.00       132\n",
      "           8       1.00      1.00      1.00       130\n",
      "           9       1.00      1.00      1.00       139\n",
      "\n",
      "    accuracy                           1.00      1347\n",
      "   macro avg       1.00      1.00      1.00      1347\n",
      "weighted avg       1.00      1.00      1.00      1347\n",
      "\n",
      "Test set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       0.94      1.00      0.97        48\n",
      "           2       1.00      0.96      0.98        50\n",
      "           3       1.00      0.97      0.99        35\n",
      "           4       0.98      0.96      0.97        46\n",
      "           5       0.96      0.94      0.95        49\n",
      "           6       1.00      1.00      1.00        44\n",
      "           7       0.96      0.98      0.97        47\n",
      "           8       0.98      0.91      0.94        44\n",
      "           9       0.91      1.00      0.95        41\n",
      "\n",
      "    accuracy                           0.97       450\n",
      "   macro avg       0.97      0.97      0.97       450\n",
      "weighted avg       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### CLASSIFY MNIST PICTURES\n",
    "\n",
    "# 'digits' is a tiny version of MNIST in sklearn.datasets has only 8 x 8 pixels\n",
    "# with grayscale values from 0 to 16\n",
    "digits = datasets.load_digits()\n",
    "data = digits.data.astype(\"float\")\n",
    "print(\"Samples: {}, Dimension: {}\".format(data.shape[0], data.shape[1]))\n",
    "\n",
    "X = data/16.0\n",
    "\n",
    "Y = digits.target\n",
    "\n",
    "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "# we need to turn the labels into 1-hot representations\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# fit the model to the training data\n",
    "model = FeedforwardNeuralNetwork([64, 32, 16, 10])\n",
    "model.fit(trainX,trainY,1000,10)\n",
    "\n",
    "# print the classification performance\n",
    "print(\"Training set accuracy\")\n",
    "\n",
    "predictedY = model.predict(trainX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "trainY = trainY.argmax(axis=1)\n",
    "\n",
    "print(classification_report(trainY, predictedY))\n",
    "\n",
    "print(\"Test set accuracy\")\n",
    "\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "testY = testY.argmax(axis=1)\n",
    "\n",
    "print(classification_report(testY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all test images were labeled correctly, 97%! But let's take a look at the ones that were labeled wrong. Most look a bit ambiguous or messy, so it's not that surprising they were not classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "The correct label is 4\n",
      "The predicted label is 7\n",
      "77\n",
      "The correct label is 2\n",
      "The predicted label is 1\n",
      "189\n",
      "The correct label is 8\n",
      "The predicted label is 7\n",
      "222\n",
      "The correct label is 2\n",
      "The predicted label is 8\n",
      "258\n",
      "The correct label is 8\n",
      "The predicted label is 1\n",
      "278\n",
      "The correct label is 5\n",
      "The predicted label is 4\n",
      "296\n",
      "The correct label is 3\n",
      "The predicted label is 5\n",
      "312\n",
      "The correct label is 5\n",
      "The predicted label is 1\n",
      "319\n",
      "The correct label is 4\n",
      "The predicted label is 9\n",
      "330\n",
      "The correct label is 7\n",
      "The predicted label is 9\n",
      "342\n",
      "The correct label is 5\n",
      "The predicted label is 9\n",
      "430\n",
      "The correct label is 8\n",
      "The predicted label is 5\n",
      "443\n",
      "The correct label is 8\n",
      "The predicted label is 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL1UlEQVR4nO3d4Ytc9RXG8edxjagxstBNRYy6FUpAhGzCEioBbROVWCVF6IsEFBta0hetuLQg2jfVf0CTF0WQqBGMEY0mFGmtARNFaLWbmNRoYtGwYpqY3UU0mkKDyemLuSlpTLt31/u7O9nz/cCQmd2ZOWd388zvzsydexwRAjCznTfdDQAoj6ADCRB0IAGCDiRA0IEECDqQQFcE3fZy2+/b/sD2/YVrPWF71PbeknVOq3el7e2299l+1/a9hetdaPst23uqeg+VrFfV7LH9tu2XSteq6o3Yfsf2btvDhWv12t5se3/1N7y+YK351c906nTU9lAjdx4R03qS1CPpQ0nXSLpA0h5J1xasd4OkRZL2tvTzXS5pUXV+jqS/F/75LOmS6vwsSW9K+l7hn/FXkp6R9FJLv9MRSX0t1XpK0s+q8xdI6m2pbo+kTyRd3cT9dcOKvljSBxFxICKOS3pW0o9KFYuI1yV9Wur+z1LvcETsqs5/IWmfpCsK1ouI+LK6OKs6FdsryvY8SbdJWl+qxnSxfak6C8PjkhQRxyPis5bKL5P0YUR81MSddUPQr5D08WmXD6pgEKaT7X5JC9VZZUvW6bG9W9KopG0RUbLeWkn3STpZsMaZQtIrtnfaXlOwzjWSxiQ9WT01WW97dsF6p1spaVNTd9YNQfdZvjbj9su1fYmkFyQNRcTRkrUi4kREDEiaJ2mx7etK1LF9u6TRiNhZ4v7/jyURsUjSrZJ+YfuGQnXOV+dp3qMRsVDSMUlFX0OSJNsXSFoh6fmm7rMbgn5Q0pWnXZ4n6dA09VKE7VnqhHxjRLzYVt1qM3OHpOWFSiyRtML2iDpPuZbafrpQrf+IiEPVv6OStqjz9K+Eg5IOnrZFtFmd4Jd2q6RdEXGkqTvshqD/VdJ3bX+neiRbKen309xTY2xbned4+yLi4RbqzbXdW52/SNJNkvaXqBURD0TEvIjoV+fv9mpE3Fmi1im2Z9uec+q8pFskFXkHJSI+kfSx7fnVl5ZJeq9ErTOsUoOb7VJn02RaRcRXtn8p6U/qvNL4RES8W6qe7U2Svi+pz/ZBSb+NiMdL1VNn1btL0jvV82ZJ+k1E/KFQvcslPWW7R50H8uciopW3vVpymaQtncdPnS/pmYh4uWC9eyRtrBahA5JWF6wl2xdLulnSzxu93+qlfAAzWDdsugMojKADCRB0IAGCDiRA0IEEuirohXdnnLZa1KPedNfrqqBLavOX2eofjnrUm8563RZ0AAUU2WGmr68v+vv7J327sbExzZ07t/F+mq515Mjkd0E+duyYZs+e2gefDh8+POnbnDx5UuedN7XH8RMnTkzpdueKgYGBSd9mfHxcfX19U6rX09Mz6dtM9f/nyMiIxsfHv/ZBsSK7wPb392t4uOiBP6bV2rVrW6334IMPtlrv888/b7Ve27Zv395qvd7e3tZqDQ4OnvXrbLoDCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUigVtDbHJkEoHkTBr06yODv1DkE7bWSVtm+tnRjAJpTZ0VvdWQSgObVCXqakUnATFUn6LVGJtleY3vY9vDY2Ng37wxAY+oEvdbIpIh4LCIGI2KwrY+aAqinTtBn9MgkIIMJP4/e9sgkAM2rdeCJak5YqVlhAApjzzggAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkUmdTStqGhoVbrrVu3rtV6bbv77rtbrXfHHXe0Wq/NySndghUdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCdQZyfSE7VHbe9toCEDz6qzoGyQtL9wHgIImDHpEvC7p0xZ6AVAIz9GBBBoLOrPXgO7VWNCZvQZ0LzbdgQTqvL22SdKfJc23fdD2T8u3BaBJdYYsrmqjEQDlsOkOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBGTF7bevWrdPdwozS9u9zw4YNrdbLiBUdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCdQ5OOSVtrfb3mf7Xdv3ttEYgObU2df9K0m/johdtudI2ml7W0S8V7g3AA2pM3vtcETsqs5/IWmfpCtKNwagOZN6jm67X9JCSW+WaAZAGbWDbvsSSS9IGoqIo2f5PrPXgC5VK+i2Z6kT8o0R8eLZrsPsNaB71XnV3ZIel7QvIh4u3xKAptVZ0ZdIukvSUtu7q9MPC/cFoEF1Zq+9Ickt9AKgEPaMAxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQwIyYvTYwMDDdLRTV29vbar09e/a0Wm9kZKTVev39/a3W6was6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUigzlFgL7T9lu091ey1h9poDEBz6uzr/i9JSyPiy+r47m/Y/mNE/KVwbwAaUucosCHpy+rirOoUJZsC0Ky6k1p6bO+WNCppW0Qwew04h9QKekSciIgBSfMkLbZ93ZnXYfYa0L0m9ap7RHwmaYek5Wf5HrPXgC5V51X3ubZ7q/MXSbpJ0v7SjQFoTp1X3S+X9JTtHnUeGJ6LiJfKtgWgSXVedf+bpIUt9AKgEPaMAxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQwIyYvbZ169bpbqGoDRs2tFpv9erVrdZre7ZcRqzoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSKB20KshDm/b5sCQwDlmMiv6vZL2lWoEQDl1RzLNk3SbpPVl2wFQQt0Vfa2k+ySdLNgLgELqTGq5XdJoROyc4HrMXgO6VJ0VfYmkFbZHJD0raantp8+8ErPXgO41YdAj4oGImBcR/ZJWSno1Iu4s3hmAxvA+OpDApA4lFRE71BmbDOAcwooOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBGTF7baZre/bajTfe2Go9Zq+Vx4oOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBGrtAlsd6vkLSSckfRURgyWbAtCsyezr/oOIGC/WCYBi2HQHEqgb9JD0iu2dtteUbAhA8+puui+JiEO2vy1pm+39EfH66VeoHgDWSNJVV13VcJsAvolaK3pEHKr+HZW0RdLis1yH2WtAl6ozTXW27Tmnzku6RdLe0o0BaE6dTffLJG2xfer6z0TEy0W7AtCoCYMeEQckLWihFwCF8PYakABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEEmL02BW3PQnvttddarffII4+0Wg/lsaIDCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQggVpBt91re7Pt/bb32b6+dGMAmlN3X/d1kl6OiB/bvkDSxQV7AtCwCYNu+1JJN0j6iSRFxHFJx8u2BaBJdTbdr5E0JulJ22/bXl8NcvgvttfYHrY9PDY21nijAKauTtDPl7RI0qMRsVDSMUn3n3klRjIB3atO0A9KOhgRb1aXN6sTfADniAmDHhGfSPrY9vzqS8skvVe0KwCNqvuq+z2SNlavuB+QtLpcSwCaVivoEbFb0mDhXgAUwp5xQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSYPbaFOzYsaPVegsWLGi13tDQUKv1UB4rOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kMCEQbc93/bu005HbbPrFHAOmXAX2Ih4X9KAJNnukfQPSVsK9wWgQZPddF8m6cOI+KhEMwDKmGzQV0raVKIRAOXUDnp1TPcVkp7/H99n9hrQpSazot8qaVdEHDnbN5m9BnSvyQR9ldhsB85JtYJu+2JJN0t6sWw7AEqoO5Lpn5K+VbgXAIWwZxyQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpCAI6L5O7XHJE3lM+t9ksYbbqcbalGPem3VuzoivvapsiJBnyrbwxExONNqUY96012PTXcgAYIOJNBtQX9shtaiHvWmtV5XPUcHUEa3regACiDoQAIEHUiAoAMJEHQggX8DqPasvP1yi9sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL40lEQVR4nO3d/4tVdR7H8dcrUyozBlZXJKvZYBEi8AsiG0K5WmFbaD/sDwobGLu4P+xGskLU/rL1D4T7wxKElUFmlKUssdsmpEWwWzvatFljUjLSrJUjMVoKK+V7f7jHxbXZnTN2Pmeu834+4OK9M/fe93tmfN3Pufeee96OCAGY3C6Z6AYAlEfQgQQIOpAAQQcSIOhAAgQdSKArgm57pe0PbX9k+8HCtZ60fdT2/pJ1zql3je3dtgdsv2/7/sL1LrP9tu13q3qPlKxX1Zxi+x3bL5euVdUbtP2e7X7bfYVr9djebvtA9Te8qWCtedXPdPZ0wvaGRu48Iib0JGmKpI8lXS9pmqR3Jd1QsN7NkhZJ2t/SzzdH0qLq/AxJBwv/fJZ0ZXV+qqS3JP2o8M/4G0nPSnq5pd/poKSZLdV6WtIvqvPTJPW0VHeKpM8kXdfE/XXDir5E0kcRcSgiTkt6TtLqUsUi4g1JX5S6/1HqfRoR+6rzX0oakHR1wXoREV9VF6dWp2J7RdmeK+lOSZtL1Zgotq9SZ2F4QpIi4nREjLRUfoWkjyPicBN31g1Bv1rSJ+dcHlLBIEwk272SFqqzypasM8V2v6SjknZFRMl6myQ9IOlMwRrnC0mv2t5re33BOtdLGpb0VPXUZLPt6QXrnWuNpG1N3Vk3BN2jfG3S7Zdr+0pJL0raEBEnStaKiG8iYoGkuZKW2L6xRB3bd0k6GhF7S9z//7E0IhZJukPSr2zfXKjOpeo8zXssIhZKOimp6GtIkmR7mqRVkl5o6j67IehDkq455/JcSUcmqJcibE9VJ+RbI+KltupWm5l7JK0sVGKppFW2B9V5yrXc9jOFav1HRByp/j0qaYc6T/9KGJI0dM4W0XZ1gl/aHZL2RcTnTd1hNwT975J+aPsH1SPZGkl/nOCeGmPb6jzHG4iIR1uoN8t2T3X+ckm3SjpQolZEPBQRcyOiV52/22sR8bMStc6yPd32jLPnJd0uqcg7KBHxmaRPbM+rvrRC0gclap1nrRrcbJc6myYTKiK+tv1rSX9R55XGJyPi/VL1bG+TtEzSTNtDkn4XEU+UqqfOqnePpPeq582S9NuI+FOhenMkPW17ijoP5M9HRCtve7VktqQdncdPXSrp2Yh4pWC9+yRtrRahQ5LuLVhLtq+QdJukXzZ6v9VL+QAmsW7YdAdQGEEHEiDoQAIEHUiAoAMJdFXQC+/OOGG1qEe9ia7XVUGX1OYvs9U/HPWoN5H1ui3oAAoossPMzJkzo7e3d9y3Gx4e1qxZsxrvp+lap06dGvdtRkZG1NPTc0H1Dh48OO7bnDlzRpdccmGP43PmzBn3bU6ePKnp0y/sg12zZ88e923a/L9yMdUbHBzUsWPHvvVBsSK7wPb29qqvr+iBPyZUf3//2Fdq0LJly1qtt3HjxlbrbdjQzEFUIC1evHjUr7PpDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQggVpBb3NkEoDmjRn06iCDf1DnELQ3SFpr+4bSjQFoTp0VvdWRSQCaVyfoaUYmAZNVnaDXGplke73tPtt9w8PD370zAI2pE/RaI5Mi4vGIWBwRi9v8OB+AsdUJ+qQemQRkMObn0dsemQSgebUOPFHNCSs1KwxAYewZByRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQggSKTWto22SentF1v3bp1rdYbGRlptd6WLVtardcNk2hY0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBAnZFMT9o+ant/Gw0BaF6dFX2LpJWF+wBQ0JhBj4g3JH3RQi8ACuE5OpBAY0Fn9hrQvRoLOrPXgO7FpjuQQJ2317ZJ+qukebaHbP+8fFsAmlRnyOLaNhoBUA6b7kACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEpgUs9d27tzZar3jx4+3Wm/Tpk2t1uvp6Wm13oIFC1qtNzg42Go9Zq8BaAVBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEqhzcMhrbO+2PWD7fdv3t9EYgObU2df9a0kbI2Kf7RmS9treFREfFO4NQEPqzF77NCL2Vee/lDQg6erSjQFozrieo9vulbRQ0lslmgFQRu2g275S0ouSNkTEiVG+z+w1oEvVCrrtqeqEfGtEvDTadZi9BnSvOq+6W9ITkgYi4tHyLQFoWp0VfamkeyQtt91fnX5SuC8ADaoze+1NSW6hFwCFsGcckABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEEJsXstcnu7rvvbrXeyMhIq/UOHz7car22Z/V1A1Z0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJFDnKLCX2X7b9rvV7LVH2mgMQHPq7Ov+L0nLI+Kr6vjub9r+c0T8rXBvABpS5yiwIemr6uLU6hQlmwLQrLqTWqbY7pd0VNKuiGD2GnARqRX0iPgmIhZImitpie0bz78Os9eA7jWuV90jYkTSHkkrR/kes9eALlXnVfdZtnuq85dLulXSgdKNAWhOnVfd50h62vYUdR4Yno+Il8u2BaBJdV51/4ekhS30AqAQ9owDEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpDApJi99vDDD090C0W1PQtty5YtrdabP39+q/VWr17dar1uwIoOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBGoHvRri8I5tDgwJXGTGs6LfL2mgVCMAyqk7kmmupDslbS7bDoAS6q7omyQ9IOlMwV4AFFJnUstdko5GxN4xrsfsNaBL1VnRl0paZXtQ0nOSltt+5vwrMXsN6F5jBj0iHoqIuRHRK2mNpNci4mfFOwPQGN5HBxIY16GkImKPOmOTAVxEWNGBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiQwKWavta3tWW9t1zt+/Hir9Xbu3NlqvYxY0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBArV1gq0M9fynpG0lfR8Tikk0BaNZ49nX/cUQcK9YJgGLYdAcSqBv0kPSq7b2215dsCEDz6m66L42II7a/L2mX7QMR8ca5V6geANZL0rXXXttwmwC+i1orekQcqf49KmmHpCWjXIfZa0CXqjNNdbrtGWfPS7pd0v7SjQFoTp1N99mSdtg+e/1nI+KVol0BaNSYQY+IQ5Lmt9ALgEJ4ew1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQALMXrsI7Nmzp9V6t9xyS6v1ent7W62XESs6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEqgVdNs9trfbPmB7wPZNpRsD0Jy6+7r/XtIrEfFT29MkXVGwJwANGzPotq+SdLOkdZIUEaclnS7bFoAm1dl0v17SsKSnbL9je3M1yOG/2F5vu8923/DwcOONArhwdYJ+qaRFkh6LiIWSTkp68PwrMZIJ6F51gj4kaSgi3qoub1cn+AAuEmMGPSI+k/SJ7XnVl1ZI+qBoVwAaVfdV9/skba1ecT8k6d5yLQFoWq2gR0S/pMWFewFQCHvGAQkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgNlrF6C/v7/Veq+//nqr9Xbv3t1qPZTHig4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiQwZtBtz7Pdf87phO0NbTQHoBlj7gIbER9KWiBJtqdI+qekHYX7AtCg8W66r5D0cUQcLtEMgDLGG/Q1kraVaARAObWDXh3TfZWkF/7H95m9BnSp8azod0jaFxGfj/ZNZq8B3Ws8QV8rNtuBi1KtoNu+QtJtkl4q2w6AEuqOZDol6XuFewFQCHvGAQkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCTgimr9Te1jShXxmfaakYw230w21qEe9tupdFxHf+lRZkaBfKNt9EbF4stWiHvUmuh6b7kACBB1IoNuC/vgkrUU96k1ova56jg6gjG5b0QEUQNCBBAg6kABBBxIg6EAC/wb2rsJSQBmCmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(testX.shape[0]):\n",
    "    if testY[i] != predictedY[i]:\n",
    "        print(i)\n",
    "        print('The correct label is', testY[i])\n",
    "        print('The predicted label is', predictedY[i])\n",
    "        plt.matshow(16*testX[i].reshape(8,8), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these images are really hard to interpret, even as a human, so it is unsurprising the model has trouble with them.\n",
    "\n",
    "## Example: Full-Size MNIST\n",
    "\n",
    "Next, let's try to use 1000 images from the full-sized MNIST dataset of 28-by-28 grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 100 loss =  7.870732365034623\n",
      "Epoch = 200 loss =  7.0341860276301205\n",
      "Epoch = 300 loss =  5.946170642042398\n",
      "Epoch = 400 loss =  5.782510087053828\n",
      "Epoch = 500 loss =  5.707416779386726\n",
      "Epoch = 600 loss =  5.661728259440102\n",
      "Epoch = 700 loss =  5.629390524860063\n",
      "Epoch = 800 loss =  5.607038488928979\n",
      "Epoch = 900 loss =  5.591276570000582\n",
      "Epoch = 1000 loss =  5.5786784758077115\n",
      "Training set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        62\n",
      "           1       0.99      0.98      0.98        89\n",
      "           2       0.96      0.97      0.97        78\n",
      "           3       1.00      1.00      1.00        70\n",
      "           4       0.99      1.00      0.99        85\n",
      "           5       0.97      1.00      0.99        70\n",
      "           6       1.00      0.97      0.99        68\n",
      "           7       0.99      0.98      0.98        86\n",
      "           8       0.99      0.99      0.99        68\n",
      "           9       1.00      0.97      0.99        74\n",
      "\n",
      "    accuracy                           0.99       750\n",
      "   macro avg       0.99      0.99      0.99       750\n",
      "weighted avg       0.99      0.99      0.99       750\n",
      "\n",
      "Test set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90        35\n",
      "           1       0.93      0.96      0.95        27\n",
      "           2       0.54      0.62      0.58        21\n",
      "           3       0.75      0.65      0.70        23\n",
      "           4       0.77      0.85      0.81        20\n",
      "           5       0.72      0.82      0.77        22\n",
      "           6       0.96      0.88      0.92        26\n",
      "           7       0.79      0.87      0.83        31\n",
      "           8       0.80      0.63      0.71        19\n",
      "           9       0.88      0.81      0.84        26\n",
      "\n",
      "    accuracy                           0.81       250\n",
      "   macro avg       0.81      0.80      0.80       250\n",
      "weighted avg       0.82      0.81      0.81       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### CLASSIFY MNIST PICTURES\n",
    "\n",
    "# create a dataset of 1000 MNIST images, reshaped as single vectors, and labels\n",
    "data = mnist.load_data()\n",
    "\n",
    "# The datapoints are in mnistData[0][0]\n",
    "X = data[0][0][:1000].reshape([1000,28*28])\n",
    "X = X/255.0\n",
    "\n",
    "# The labels are in mnistData[0][1]\n",
    "Y = data[0][1][:1000]\n",
    "\n",
    "# randomly choose 75% of the data to be the training set and 25% for the testing set\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.25)\n",
    "\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# fit the model to the training data\n",
    "model = FeedforwardNeuralNetwork([784, 16, 10], 0.5)\n",
    "model.fit(trainX,trainY,1000,100)\n",
    "\n",
    "# print the classification performance\n",
    "print(\"Training set accuracy\")\n",
    "predictedY = model.predict(trainX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "trainY = trainY.argmax(axis=1)\n",
    "print(classification_report(trainY, predictedY))\n",
    "\n",
    "print(\"Test set accuracy\")\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have an **overfitting** problem because the training accuracy is good, but test accuracy is significantly worse. This frequently happens when we use a small dataset. In this case, we used only 1000 images, but it still took a several minutes to run. If we used 10000 images, which would be a more ideal dataset, it would take 30-40 minutes!\n",
    "\n",
    "This is no good... we need stochastic gradient descent to make this more useful on larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8 - Sept 16 - Stochastic Gradient Descent\n",
    "\n",
    "We already know what gradient descent is: we run our model on training data, compute the loss function, find the gradient of the loss function, and update our parameters in the opposite direction of the gradient by a small amount; and repeat this until the model converges. The same general approach is used in nearly all neural networks.\n",
    "\n",
    "In linear regression and logistic classification, we were computing the outputs and loss function for the entire dataset (usually multiple times) per iteration of gradient descent, making a weight update based on the gradient, and repeating.\n",
    "\n",
    "The typical approach used in modern neural networks is **stochastic** gradient descent (SGD). SGD updates weights after processing a random sample, called a **mini-batch**, of datapoints: enough points to reduce the variance of using just one for more stable convergence of parameters but not so much that the computation is too expensive. In this way, we process a mini-batch for outputs, compute an approximate loss function and approximate gradients, update weights, and repeat.\n",
    "\n",
    "#### How large should our mini-batches be?\n",
    "\n",
    "Typically, using $2^n$ for something like $n=5, 6, 7, 8$ because these values tend to be ideal for the linear algebra optimization libraries we use (NumPy, TensorFlow, etc). The mini-batch size is a hyperparameter, but it generally isn't one you need to tweak too much.\n",
    "\n",
    "One exception is if you are using GPUs for computing: then, it's typically best to choose the largest power of 2 that allows a whole mini-batch to fit into GPU memory, which will result in the underlying linear algebra libraries working optimally.\n",
    "\n",
    "## Implementing SGD\n",
    "\n",
    "Once we implement SGD with backpropagation, we will have constructed a \"vanilla\" neural network, which is probably the simplest neural network that is of practical use.\n",
    "\n",
    "First, let's import some libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will write a class similar to the `FeedforwardNeuralNetwork` class we wrote previously but upgraded to use SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetworkSGD:\n",
    "    \n",
    "    # input a vector [a, b, c, ...] with the number of nodes in each layer\n",
    "    def __init__(self, layers, alpha = 0.1, batchSize = 32):\n",
    "        # list of weight matrices between layers\n",
    "        self.W = []\n",
    "        \n",
    "        # network architecture will be a vector of numbers of nodes for each layer\n",
    "        self.layers = layers\n",
    "        \n",
    "        # learning rate\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # batch size\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "        # initialize the weights (randomly) -- this is our initial guess for gradient descent\n",
    "        \n",
    "        # initialize the weights between layers (up to the next-to-last one) as normal random variables\n",
    "        for i in np.arange(0, len(layers) - 2):\n",
    "            self.W.append(np.random.randn(layers[i] + 1, layers[i + 1] + 1))\n",
    "            \n",
    "        # initialize weights between the last two layers (we don't want bias for the last one)\n",
    "        self.W.append(np.random.randn(layers[-2] + 1, layers[-1]))\n",
    "        \n",
    "    # define the sigmoid activation\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    # define the sigmoid derivative (where z is the output of a sigmoid)\n",
    "    def sigmoidDerivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def getNextBatch(self, X, y, batchSize):\n",
    "        for i in np.arange(0, X.shape[0], batchSize):\n",
    "            yield (X[i:i + batchSize], y[i:i + batchSize])\n",
    "    \n",
    "    # fit the model\n",
    "    def fit(self, X, y, epochs = 10000, update = 1000):\n",
    "        # add a column of ones to the end of X\n",
    "        X = np.hstack((X, np.ones([X.shape[0],1])))\n",
    "\n",
    "        for epoch in np.arange(0,epochs):\n",
    "            \n",
    "            # randomize the examples\n",
    "            p = np.arange(0,X.shape[0])\n",
    "            np.random.shuffle(p)\n",
    "            X = X[p]\n",
    "            y = y[p]\n",
    "\n",
    "            # feed forward, backprop, and weight update\n",
    "            for (x, target) in self.getNextBatch(X, y, self.batchSize):\n",
    "                # make a list of output activations from the first layer\n",
    "                # (just the original x values)\n",
    "                A = [np.atleast_2d(x)]\n",
    "                \n",
    "                # feed forward\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    \n",
    "                    # feed through one layer and apply sigmoid activation\n",
    "                    net = A[layer].dot(self.W[layer])\n",
    "                    out = self.sigmoid(net)\n",
    "                    \n",
    "                    # add our network output to the list of activations\n",
    "                    A.append(out)\n",
    "                    \n",
    "                # backpropagation (coming soon!)\n",
    "                error = A[-1] - target\n",
    "                \n",
    "                D = [error * self.sigmoidDerivative(A[-1])]\n",
    "                \n",
    "                # loop backwards over the layers to build up deltas\n",
    "                for layer in np.arange(len(A) - 2, 0, -1):\n",
    "                    delta = D[-1].dot(self.W[layer].T)\n",
    "                    delta = delta * self.sigmoidDerivative(A[layer])\n",
    "                    D.append(delta)\n",
    "                    \n",
    "                # reverse the deltas since we looped in reverse\n",
    "                D = D[::-1]\n",
    "                \n",
    "                # weight update\n",
    "                for layer in np.arange(0, len(self.W)):\n",
    "                    self.W[layer] -= self.alpha * A[layer].T.dot(D[layer])\n",
    "                    \n",
    "            if (epoch + 1) % update == 0:\n",
    "                loss = self.computeLoss(X,y)\n",
    "                print('Epoch =', epoch + 1, '\\t loss =', loss)\n",
    "                \n",
    "    def predict(self, X, addOnes = True):\n",
    "        # initialize data, be sure it's the right dimension\n",
    "        p = np.atleast_2d(X)\n",
    "        \n",
    "        # add a column of 1s for bias\n",
    "        if addOnes:\n",
    "            p = np.hstack((p, np.ones([X.shape[0],1])))\n",
    "        \n",
    "        # feed forward!\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
    "            \n",
    "        return p\n",
    "    \n",
    "    def computeLoss(self, X, y):\n",
    "        # initialize data, be sure it's the right dimension\n",
    "        y = np.atleast_2d(y)\n",
    "        \n",
    "        # feed the datapoints through the network to get predicted outputs\n",
    "        predictions = self.predict(X, addOnes = False)\n",
    "        loss = np.sum((predictions - y)**2) / 2.0\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: MNIST\n",
    "\n",
    "As promised, this SGD neural net should run faster, so let's try to use the full 60,000 training images available in MNIST and 10,000 test images. (This is still a LOT of computation, using 70000 total 28-by-28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 loss = 5114.252384701645\n",
      "Epoch = 2 loss = 3827.640450070584\n",
      "Epoch = 3 loss = 3473.3288513337393\n",
      "Epoch = 4 loss = 2993.842063360823\n",
      "Epoch = 5 loss = 2901.9404384637314\n",
      "Epoch = 6 loss = 2630.701667897917\n",
      "Epoch = 7 loss = 2464.5746902285573\n",
      "Epoch = 8 loss = 2795.425929393308\n",
      "Epoch = 9 loss = 2364.3985255987027\n",
      "Epoch = 10 loss = 2353.410652586407\n",
      "Epoch = 11 loss = 2215.9648653618037\n",
      "Epoch = 12 loss = 2128.7799963404223\n",
      "Epoch = 13 loss = 2262.336653846681\n",
      "Epoch = 14 loss = 1974.6134364267582\n",
      "Epoch = 15 loss = 1940.664549489394\n",
      "Epoch = 16 loss = 2430.3313501223215\n",
      "Epoch = 17 loss = 2075.9776717066957\n",
      "Epoch = 18 loss = 2329.289774857599\n",
      "Epoch = 19 loss = 1993.931256521833\n",
      "Epoch = 20 loss = 1799.237987718006\n",
      "Epoch = 21 loss = 1747.4760865779667\n",
      "Epoch = 22 loss = 1755.3602538310915\n",
      "Epoch = 23 loss = 1909.9185042697188\n",
      "Epoch = 24 loss = 1860.02112009211\n",
      "Epoch = 25 loss = 1821.339117683481\n",
      "Epoch = 26 loss = 1844.2668468960146\n",
      "Epoch = 27 loss = 1662.565576476386\n",
      "Epoch = 28 loss = 1828.9521264206987\n",
      "Epoch = 29 loss = 1926.414791181462\n",
      "Epoch = 30 loss = 1622.635249632976\n",
      "Epoch = 31 loss = 1687.1826722341666\n",
      "Epoch = 32 loss = 1510.8419745902745\n",
      "Epoch = 33 loss = 1484.0499705336379\n",
      "Epoch = 34 loss = 1660.9501294972274\n",
      "Epoch = 35 loss = 1503.9626019008072\n",
      "Epoch = 36 loss = 1490.3109687805436\n",
      "Epoch = 37 loss = 1599.7191946003888\n",
      "Epoch = 38 loss = 1461.3507954358042\n",
      "Epoch = 39 loss = 1621.275642912683\n",
      "Epoch = 40 loss = 1444.7766004882224\n",
      "Epoch = 41 loss = 1410.2368800679865\n",
      "Epoch = 42 loss = 1616.9435023963501\n",
      "Epoch = 43 loss = 1348.2703087436303\n",
      "Epoch = 44 loss = 1848.6570281302577\n",
      "Epoch = 45 loss = 1577.1092088193052\n",
      "Epoch = 46 loss = 1510.870190363473\n",
      "Epoch = 47 loss = 1406.4326198755389\n",
      "Epoch = 48 loss = 1460.894174320443\n",
      "Epoch = 49 loss = 1566.7977650538458\n",
      "Epoch = 50 loss = 1365.9266919553145\n",
      "Epoch = 51 loss = 1336.0557729110642\n",
      "Epoch = 52 loss = 1389.8273061964442\n",
      "Epoch = 53 loss = 1514.7330184486227\n",
      "Epoch = 54 loss = 1401.3044100375325\n",
      "Epoch = 55 loss = 1316.4457293590162\n",
      "Epoch = 56 loss = 1278.9040967323847\n",
      "Epoch = 57 loss = 1336.3043801752149\n",
      "Epoch = 58 loss = 1370.8269588383225\n",
      "Epoch = 59 loss = 1158.834571840838\n",
      "Epoch = 60 loss = 1401.4670505932504\n",
      "Epoch = 61 loss = 1418.414063653836\n",
      "Epoch = 62 loss = 1384.8042826630692\n",
      "Epoch = 63 loss = 1276.41016098969\n",
      "Epoch = 64 loss = 1448.4473275062608\n",
      "Epoch = 65 loss = 1312.9833002366734\n",
      "Epoch = 66 loss = 1262.940780245831\n",
      "Epoch = 67 loss = 1257.0394151322962\n",
      "Epoch = 68 loss = 1706.8856972615536\n",
      "Epoch = 69 loss = 1317.984312729474\n",
      "Epoch = 70 loss = 1273.9877852975926\n",
      "Epoch = 71 loss = 1093.9643866091915\n",
      "Epoch = 72 loss = 1321.4498640633585\n",
      "Epoch = 73 loss = 1137.8832326738352\n",
      "Epoch = 74 loss = 1299.2896668228004\n",
      "Epoch = 75 loss = 1182.9337016981935\n",
      "Epoch = 76 loss = 1233.7441907511172\n",
      "Epoch = 77 loss = 1226.3102357965165\n",
      "Epoch = 78 loss = 1137.2027107557876\n",
      "Epoch = 79 loss = 1461.163035237853\n",
      "Epoch = 80 loss = 1335.699370097802\n",
      "Epoch = 81 loss = 1524.9822370427632\n",
      "Epoch = 82 loss = 1121.7278778805778\n",
      "Epoch = 83 loss = 1265.9147558827858\n",
      "Epoch = 84 loss = 1372.7577320546538\n",
      "Epoch = 85 loss = 1255.9770359669906\n",
      "Epoch = 86 loss = 1214.0210069863815\n",
      "Epoch = 87 loss = 1202.3187923097348\n",
      "Epoch = 88 loss = 1138.6461682253075\n",
      "Epoch = 89 loss = 1224.2085727692222\n",
      "Epoch = 90 loss = 1225.5746387693137\n",
      "Epoch = 91 loss = 1245.9589825938483\n",
      "Epoch = 92 loss = 1083.3074920111872\n",
      "Epoch = 93 loss = 1166.547605431623\n",
      "Epoch = 94 loss = 1468.667005014194\n",
      "Epoch = 95 loss = 1214.0119881803223\n",
      "Epoch = 96 loss = 1131.7905609514546\n",
      "Epoch = 97 loss = 1155.8022552430532\n",
      "Epoch = 98 loss = 1121.3988365246678\n",
      "Epoch = 99 loss = 1207.19726478228\n",
      "Epoch = 100 loss = 1288.2108884631305\n",
      "Training set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      5923\n",
      "           1       0.99      0.98      0.99      6742\n",
      "           2       0.96      0.98      0.97      5958\n",
      "           3       0.96      0.96      0.96      6131\n",
      "           4       0.98      0.99      0.98      5842\n",
      "           5       0.96      0.97      0.96      5421\n",
      "           6       0.98      0.98      0.98      5918\n",
      "           7       0.98      0.98      0.98      6265\n",
      "           8       0.97      0.95      0.96      5851\n",
      "           9       0.97      0.97      0.97      5949\n",
      "\n",
      "    accuracy                           0.97     60000\n",
      "   macro avg       0.97      0.97      0.97     60000\n",
      "weighted avg       0.97      0.97      0.97     60000\n",
      "\n",
      "Test set accuracy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.94      0.95      1032\n",
      "           3       0.93      0.95      0.94      1010\n",
      "           4       0.96      0.96      0.96       982\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.95      0.96      0.96       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.95      0.92      0.94       974\n",
      "           9       0.94      0.94      0.94      1009\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### CLASSIFY MNIST PICTURES\n",
    "\n",
    "# load the full MNIST dataset: both data and labels\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
    "\n",
    "# scale the data to values in [0,1]\n",
    "trainX = trainX.astype('float32')/255.0\n",
    "testX = testX.astype('float32')/255.0\n",
    "\n",
    "# reshape the data\n",
    "trainX = trainX.reshape([60000, 28*28])\n",
    "testX = testX.reshape([10000, 28*28])\n",
    "\n",
    "# convert the digits to one-hot vectors\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "# fit the model to the training data\n",
    "model = FeedforwardNeuralNetworkSGD([784, 32, 16, 10], 0.5, 32)\n",
    "model.fit(trainX, trainY, 100, 1)\n",
    "\n",
    "# print the classification performance\n",
    "print(\"Training set accuracy\")\n",
    "predictedY = model.predict(trainX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "trainY = trainY.argmax(axis=1)\n",
    "print(classification_report(trainY, predictedY))\n",
    "\n",
    "print(\"Test set accuracy\")\n",
    "predictedY = model.predict(testX)\n",
    "predictedY = predictedY.argmax(axis=1)\n",
    "\n",
    "testY = testY.argmax(axis=1)\n",
    "print(classification_report(testY, predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test accuracy on MNIST jumped from mid-80\\% previously to 95\\% with our implementation using SGD and the full dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
