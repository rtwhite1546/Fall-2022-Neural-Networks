{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9cPpBDMtZhK",
    "tags": []
   },
   "source": [
    "# MTH 4320/5320 Python Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb4gSaIPtfNo"
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "\n",
    "(a) Write a function that takes one input, which can be an integer or a string, checks if the input integer or string is a palindrome, prints a message stating the datetype and whether or not it is a palindrome, returns True if it is a palindrome, and returns False if not.\n",
    "\n",
    "If a different datatype is input to the function, it should print a descriptive failure message, but it should **not** return anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j2-YofTstOG3"
   },
   "outputs": [],
   "source": [
    "def is_palindrome(input, verbose = True):\n",
    "    \n",
    "    input_type = type(input)\n",
    "    \n",
    "    if verbose: print('The input is of type', input_type)\n",
    "\n",
    "    if input_type is not int and input_type is not str:\n",
    "        print('is_palindrome failed: the inputmust be a string or integer')\n",
    "\n",
    "    else:\n",
    "        if input_type is int:\n",
    "            input = str(input)\n",
    "\n",
    "        if input == input[::-1]:\n",
    "            if verbose: print(input, 'is a palindrome')\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            if verbose: print(input, 'is not a palindrome')\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHv6hHaNvyR0"
   },
   "source": [
    "(b) Run it for some examples of strings and integers that are and are not palindromes and examples of other datatypes to demonstrate it works.\n",
    "\n",
    "We will run it for\n",
    "\n",
    "* 2 integers that are palindromes\n",
    "* 2 integers that are not palindromes\n",
    "* 2 strings that are palindromes\n",
    "* 2 strings that are not palindromes\n",
    "* 2 non-integer, non-string inputs to demonstrate failure behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "himGIwAcvDsk",
    "outputId": "a54bf434-35ad-4943-abe1-9db6332d72c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is of type <class 'int'>\n",
      "1991 is a palindrome\n",
      "True \n",
      "\n",
      "The input is of type <class 'int'>\n",
      "3289823 is a palindrome\n",
      "True \n",
      "\n",
      "The input is of type <class 'int'>\n",
      "43 is not a palindrome\n",
      "False \n",
      "\n",
      "The input is of type <class 'int'>\n",
      "412 is not a palindrome\n",
      "False \n",
      "\n",
      "The input is of type <class 'str'>\n",
      "deified is a palindrome\n",
      "True \n",
      "\n",
      "The input is of type <class 'str'>\n",
      "racecar is a palindrome\n",
      "True \n",
      "\n",
      "The input is of type <class 'str'>\n",
      "wtf is not a palindrome\n",
      "False \n",
      "\n",
      "The input is of type <class 'str'>\n",
      "neural networks is not a palindrome\n",
      "False \n",
      "\n",
      "The input is of type <class 'list'>\n",
      "is_palindrome failed: the inputmust be a string or integer\n",
      "None \n",
      "\n",
      "The input is of type <class 'float'>\n",
      "is_palindrome failed: the inputmust be a string or integer\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "int_palindrome = [1991, 3289823]\n",
    "int_not_palindrome = [43, 412]\n",
    "\n",
    "str_palindrome = ['deified', 'racecar']\n",
    "str_not_palindrome = ['wtf', 'neural networks']\n",
    "\n",
    "not_int_not_string = [[1, 9, 9, 1], 58.303]\n",
    "\n",
    "test_cases = int_palindrome + int_not_palindrome\n",
    "test_cases += str_palindrome + str_not_palindrome\n",
    "test_cases += not_int_not_string\n",
    "\n",
    "for x in test_cases:\n",
    "    print(is_palindrome(x), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnKS2em-ynKL"
   },
   "source": [
    "(c) Use your function in a loop to find all palindromes in the Academic Advising text transcript from the [Michigan Corpus of Academic Spoken English](https://quod.lib.umich.edu/cgi/c/corpus/corpus?c=micase;cc=micase;view=transcript;id=ADV700JU047).\n",
    "\n",
    "(d) Write some code to construct a list of the unique palindromes in the text.\n",
    "\n",
    "First, let's extract the text from the URL and clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oosiQ0KNvGlv"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# open URL\n",
    "url = 'https://quod.lib.umich.edu/cgi/c/corpus/corpus?c=micase;cc=micase;view=transcript;id=ADV700JU047'\n",
    "html = urlopen(url).read()\n",
    "\n",
    "# create an html parser\n",
    "soup = BeautifulSoup(html, features = 'html.parser')\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "\n",
    "# remove symbols\n",
    "for char in '()/<>:[].!?-\\'':\n",
    "    text = text.replace(char, ' ')\n",
    "\n",
    "# make text all lowercase\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJlZ-fdozC9O",
    "outputId": "1d62e6ec-89e9-4485-a7aa-384ebfe734ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xx', 'mhm', 'mm', 'stats', 'did', 'll', 'level', 'nitin', 'non', 'yay', 'ss', 'refer', '11', 'wow', 'sees', 'huh', 'ele']\n"
     ]
    }
   ],
   "source": [
    "# split text into words\n",
    "words = text.split()\n",
    "\n",
    "# create a list to store palindromes\n",
    "palindromes = []\n",
    "\n",
    "# loop over the words\n",
    "for word in words:\n",
    "    if word not in palindromes and len(word) > 1:\n",
    "        if is_palindrome(word, verbose = False):\n",
    "            palindromes.append(word)\n",
    "\n",
    "print(palindromes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X3l-WGp5xGi"
   },
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKxaq4Mo52Se"
   },
   "source": [
    "(a) Write a function that uses gradient descent that attempts to minimize an input function of two variables, but instead of just one starting point, create a grid of starting points evenly spaced within a region $[-c, c]\\times [-c, c]$ for user-input $c$, and a number of grid points $b^2$ for user-input $b$.\n",
    "\n",
    "The function should run multiple instances of gradient descent methods, one starting at each of the gridpoints, and return the coordinates of the best minimum that was found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKYrAtJM53zX"
   },
   "source": [
    "Let's bring in the gradient descent code from class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YTwk7VvL5WfX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# estimate the gradient\n",
    "def computeGradient(f, x, h):\n",
    "    n = len(x)\n",
    "    gradient = np.zeros(n)\n",
    "    \n",
    "    for counter in range(n):\n",
    "        xUp = x.copy()\n",
    "        xUp[counter] += h\n",
    "        gradient[counter] = (f(xUp) - f(x))/h\n",
    "            \n",
    "    return gradient\n",
    "\n",
    "# run gradient descent and output the coordinates of the estimated critical point\n",
    "def gradientDescent(f, x0, alpha, h, tolerance, maxIterations, verbose = True):\n",
    "    # set x equal to the initial guess\n",
    "    x = x0\n",
    "\n",
    "    # take up to maxIterations number of steps\n",
    "    for counter in range(maxIterations):\n",
    "        # update the gradient\n",
    "        gradient = computeGradient(f, x, h)\n",
    "        \n",
    "        # stop if the norm of the gradient is near 0 (success)\n",
    "        if np.linalg.norm(gradient) < tolerance:\n",
    "            if verbose: print('Gradient descent took', counter, 'iterations to converge')\n",
    "            if verbose: print('The norm of the gradient is', np.linalg.norm(gradient))\n",
    "            \n",
    "            # return the approximate critical point x\n",
    "            return x\n",
    "        \n",
    "        # print a message if we do not converge (failure)\n",
    "        elif counter == maxIterations-1:\n",
    "            if verbose:\n",
    "                print(\"Gradient descent failed\")\n",
    "                print('The gradient is', gradient)\n",
    "            \n",
    "            # return x, sometimes it is still pretty good\n",
    "            return x\n",
    "        \n",
    "        # take a step in the opposite direction as the gradient\n",
    "        x -= alpha*gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUQM50ED6Pnz"
   },
   "source": [
    "Now, we solve (a)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y7N0B6vy6Nhp"
   },
   "outputs": [],
   "source": [
    "def gridGradientDescent(c, b, f, alpha, h, tolerance, maxIterations):\n",
    "    # create grid intersection points\n",
    "    x_space = np.linspace(-1 * c, c, b)\n",
    "    y_space = np.linspace(-1 * c, c, b)\n",
    "\n",
    "    # initialize the best input and output (minimum)\n",
    "    best_output = np.Inf\n",
    "    best_input = 0\n",
    "\n",
    "    # initialize \n",
    "    converged_inputs = []\n",
    "    converged_outputs = []\n",
    "\n",
    "    # loop over x values of grid intersections\n",
    "    for x in x_space:\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "\n",
    "        # loop over y values of grid intersections\n",
    "        for y in y_space:\n",
    "\n",
    "            # run gradient descent from grid intersection to get (x,y) positions\n",
    "            # gradient descent converged to\n",
    "            converged_input = gradientDescent(f, [x, y], alpha, h, tolerance, maxIterations, False)\n",
    "            inputs.append(converged_input)\n",
    "\n",
    "            # compute the output at the (x,y) gradient descent converged to\n",
    "            converged_output = f(converged_input)\n",
    "            outputs.append(converged_output)\n",
    "\n",
    "            # if the current minimum is better than previous ones, save it\n",
    "            if converged_output < best_output:\n",
    "                best_input = converged_input\n",
    "                best_output = converged_output\n",
    "                \n",
    "        converged_inputs.append(inputs)\n",
    "        converged_outputs.append(outputs)\n",
    "\n",
    "    # return the best input, best minimum, and all minima\n",
    "    return best_input, best_output, converged_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fCOJE5q9YDW"
   },
   "source": [
    "(b) Create a Python function for the mathematical function\n",
    "\n",
    "$$f(x,y)=3(1-x)^2e^{-x^2-(y+1)^2}-10\\left(\\frac{x}{5}-x^3-y^5\\right)e^{-x^2-y^2}-\\frac{1}{3}e^{-(x+1)^2-y^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XmNCS15e8RBn"
   },
   "outputs": [],
   "source": [
    "def f(input):\n",
    "    x = input[0]\n",
    "    y = input[1]\n",
    "\n",
    "    term1 = 3 * (1 - x)**2 * np.exp(-x**2 - (y + 1)**2)\n",
    "    term2 = 10 * (x/5 - x**3 - y**5) * np.exp(-x**2 - y**2)\n",
    "    term3 = (1/3) * np.exp(-(x + 1)**2 - y**2)\n",
    "\n",
    "    return term1 - term2 - term3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NssUDhKl9o3W"
   },
   "source": [
    "(c) Use your gradient descent function in $[-5,5]\\times[-5,5]$ for a range of $b$ values. For each, plot a heat map of the function value gradient descent converges to at each grid point.\n",
    "\n",
    "[*Hint.* Consider the `matplotlib` library.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "id": "XyAipDdO8Pmm",
    "outputId": "019c6fe7-cdd3-458d-baa4-efdaa864bd08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b is 3\n",
      "The converged input is [0.29203318 0.31461682]\n",
      "The best minimum is -0.0646485150802468 \n",
      "\n",
      "b is 5\n",
      "The converged input is [ 0.22169132 -1.63150822]\n",
      "The best minimum is -6.550350615825662 \n",
      "\n",
      "b is 10\n",
      "The converged input is [ 0.22264357 -1.63117796]\n",
      "The best minimum is -6.55048913893635 \n",
      "\n",
      "b is 20\n",
      "The converged input is [ 0.22267123 -1.63116594]\n",
      "The best minimum is -6.550493234848103 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x576 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# range of b values to use\n",
    "b_list = [3, 5, 10, 20]\n",
    "\n",
    "# use [-5, 5] x [-5, 5]\n",
    "c = 5\n",
    "\n",
    "cbar = False\n",
    "\n",
    "# create subplot axes\n",
    "fig, axes = plt.subplots(1, len(b_list), figsize = (30, 8))\n",
    "\n",
    "# loop over b values\n",
    "for k, b in enumerate(b_list):\n",
    "    print('b is', b)\n",
    "\n",
    "    # compute grid gradient descent to find best input, minimum, and matrix of\n",
    "    # outputs when starting from each grid intersection\n",
    "    input, output, converged_outputs = gridGradientDescent(c, b, f, 0.01, 0.01, 0.01, 1000)\n",
    "\n",
    "    print('The converged input is', input)\n",
    "    print('The best minimum is', output, '\\n')\n",
    "\n",
    "    # plot a heatmap of converged outputs\n",
    "    if b == b_list[-1]: cbar = True\n",
    "    \n",
    "    sns.heatmap(converged_outputs, vmin = -7, vmax = 0, xticklabels = False, yticklabels = False, ax=axes[k], cbar = cbar)\n",
    "    axes[k].set_title('Heat map for b = ' + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zacIOUhMDBY"
   },
   "source": [
    "As $b$ grows, the mesh of starting points becomes finer, and we are more likely to find the global minimum."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
